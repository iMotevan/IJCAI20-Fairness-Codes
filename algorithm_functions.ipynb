{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, copy, os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt.base import matrix as m\n",
    "from cvxopt import solvers\n",
    "from cvxopt.modeling import op, dot, variable, max, min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_unique_ids(objects):\n",
    "    for idx, obj in enumerate(objects):\n",
    "        obj.set_unique_id(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driver:\n",
    "    def __init__(self, d_id, driver_race, driver_gender, pickup_lat_bin, pickup_long_bin, Bu):\n",
    "        self.d_id = d_id\n",
    "        self.gender = driver_gender\n",
    "        self.race = driver_race\n",
    "        self.latitude = pickup_lat_bin\n",
    "        self.longitude = pickup_long_bin\n",
    "#         self.quota = quota\n",
    "        self.Bu = Bu\n",
    "        self.is_present = True\n",
    "    \n",
    "    def set_unique_id(self, u_id):\n",
    "        # This is the unique ID used to index the edge matrix. \n",
    "        # To find the probability of a driver u accepting a ride of type v, see the entry mat[u.u_id][v.u_id]\n",
    "        self.u_id = u_id\n",
    "    \n",
    "    def __key(self):\n",
    "#         return (self.gender, self.race, self.latitude, self.longitude)\n",
    "        return (self.d_id)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.__key())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"U_id: {}, Gender: {}, Race: {}, Lat bin: {}, Long bin: {}, Bu: {}\".format(self.u_id, self.gender, self.race,\n",
    "                                                                                  self.latitude, self.longitude,\n",
    "                                                                                  self.Bu)\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Driver):\n",
    "            return self.__key() == other.__key()\n",
    "        return NotImplemented\n",
    "\n",
    "class Request:\n",
    "    def __init__(self, pickup_lat_bin, pickup_long_bin, dropoff_lat_bin, dropoff_long_bin, \n",
    "                     requests_gender, requests_race, arrival_rate, distance, quota):\n",
    "        self.gender = requests_gender\n",
    "        self.race = requests_race\n",
    "        self.start_latitude = pickup_lat_bin\n",
    "        self.start_longitude = pickup_long_bin\n",
    "        self.end_latitude = dropoff_lat_bin\n",
    "        self.end_longitude = dropoff_long_bin\n",
    "        self.arrival_rate = arrival_rate\n",
    "        self.distance = distance\n",
    "        self.quota = quota\n",
    "    \n",
    "    def set_unique_id(self, u_id):\n",
    "        # This is the unique ID used to index the edge matrix. \n",
    "        # To find the probability of a driver u accepting a ride of type v, see the entry mat[u.u_id][v.u_id]\n",
    "        self.u_id = u_id\n",
    "\n",
    "    def __key(self):\n",
    "        return (self.gender, self.race, self.start_latitude, self.start_longitude, \n",
    "                self.end_latitude, self.end_longitude)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.__key())\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Gender: {}, Race: {}, Quota: {}, Arrival Rate:{}, Start Lat bin: {}, Start Long bin: {}, End Lat bin: {}, End Long bin: {}\"\\\n",
    "                .format(self.gender, self.race, self.quota, self.arrival_rate, self.start_latitude, self.start_longitude, \n",
    "                                     self.end_latitude, self.end_longitude)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, Request):\n",
    "            return self.__key() == other.__key()\n",
    "        return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_to_index(i, j, probability_matrix):\n",
    "    \"\"\"Given a i,j in the probability matrix, convert to the index of the x_f vector\"\"\"\n",
    "    edges_count = np.count_nonzero(probability_matrix[:i,:] != -1) + np.count_nonzero(probability_matrix[i,:j] != -1)\n",
    "    # count the number of edges of drivers before i and  count the number of edges of ith driver before request j\n",
    "    return edges_count\n",
    "\n",
    "def index_to_coordinate(idx, probability_matrix):\n",
    "    return list(zip(*np.where(probability_matrix != -1)))[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_objective(x_fair, probability_matrix, requests):\n",
    "    # Minimize the negative of the objective function (same as maximizing the objective function)\n",
    "    all_requests_fairness = []\n",
    "    for j in range(probability_matrix.shape[1]):\n",
    "        mask = [0] * len(x_fair)\n",
    "        for i in np.where(probability_matrix[:,j] != -1)[0]:\n",
    "#             print (len(mask), coordinate_to_index(i, j, probability_matrix), i, j, probability_matrix.shape, len(requests))\n",
    "            mask[coordinate_to_index(i, j, probability_matrix)] = \\\n",
    "                -1 * (probability_matrix[i, j]/requests[j].arrival_rate)\n",
    "#         print(m(mask), x_fair)\n",
    "        all_requests_fairness.append(dot(m(mask), x_fair))\n",
    "    fairness = max(all_requests_fairness) # solver would minimize this\n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fairness_objective_offpeak(x_fair, probability_matrix, drivers):\n",
    "    # Minimize the negative of the objective function (same as maximizing the objective function)\n",
    "#     all_requests_fairness = []\n",
    "    all_drivers_fairness= []\n",
    "    for i in range(probability_matrix.shape[0]):\n",
    "        mask = [0] * len(x_fair)\n",
    "        for j in np.where(probability_matrix[i,:] != -1)[0]:\n",
    "#             print (len(mask), coordinate_to_index(i, j, probability_matrix), i, j, probability_matrix.shape, len(drivers))\n",
    "            mask[coordinate_to_index(i, j, probability_matrix)] = \\\n",
    "                -1 * (probability_matrix[i, j]/drivers[i].Bu)\n",
    "#         print(len(m(mask)), len(x_fair))\n",
    "        all_drivers_fairness.append(dot(m(mask), x_fair))\n",
    "    fairness = max(all_drivers_fairness) # solver would minimize this\n",
    "    return fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit_objective(x_f, probability_matrix, profit_matrix):\n",
    "    c = []\n",
    "    for i, j in zip(*np.where(probability_matrix != -1)):\n",
    "        c.append(-1 * profit_matrix[i,j] * probability_matrix[i,j]) # multiply by -1 since we want to maximise w_f * x_f * p_f but cvxopt minimizes the objective function by default, since minimizing -obj is same as maximizing obj, we multiply our profit objective by a minus sign\n",
    "    assert len(c) == len(x_f)\n",
    "    c = m(c)\n",
    "    profit = dot(c, x_f)\n",
    "    c, x_f\n",
    "    return profit, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_inequalities(x, probability_matrix, requests, return_coefficients=False):\n",
    "#     offset = 0\n",
    "#     A, b = [], [] # model all inequalities as A * x <= b\n",
    "#     # models the inequalities 3 and 4 in the writeup\n",
    "#     for i in range(probability_matrix.shape[0]): # iterate over all drivers\n",
    "#         a1, a2 = [0] * len(x), [0] * len(x) # coefficients of inequalities\n",
    "#         edges_count = np.count_nonzero(probability_matrix[i] != -1)\n",
    "#         edges_probabilities = probability_matrix[i][np.where(probability_matrix[i] != -1)]\n",
    "#         assert len(edges_probabilities) == edges_count # sanity check\n",
    "#         a1[offset:offset + edges_count] = edges_probabilities\n",
    "#         a2[offset:offset + edges_count] = [1] * edges_count\n",
    "#         A.append(a1)\n",
    "#         A.append(a2)\n",
    "#         b.append(1)\n",
    "#         b.append(drivers[i].quota)\n",
    "#         offset += edges_count\n",
    "#     # Models the inequality -1 * x_f <= 0 for all edges\n",
    "#     for i in range(len(x)):\n",
    "#         a1 = [0] * len(x)\n",
    "#         a1[i] = -1\n",
    "#         A.append(a1)\n",
    "#         b.append(0)\n",
    "#     # Models inequality 5 in the writeup\n",
    "#     for j in range(probability_matrix.shape[1]):# iterate over all request types\n",
    "#         # j -> request; i-> driver\n",
    "#         a1 = [0] * len(x)\n",
    "#         for i in np.where(probability_matrix[:,j] != -1)[0]:\n",
    "#             a1[coordinate_to_index(i, j, probability_matrix)] = 1\n",
    "#         A.append(a1)\n",
    "#         b.append(requests[j].arrival_rate)\n",
    "#     print (len(A), len(b), len(A[0]), len(x))\n",
    "\n",
    "#     A, b = m(A).T, m(b)\n",
    "\n",
    "#     if not return_coefficients:\n",
    "#         print (type(A*x))\n",
    "#         inequality = (A * x <= b)\n",
    "#         return inequality\n",
    "#     else:\n",
    "#         return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inequalities_offpeak(x, probability_matrix, drivers, requests, return_coefficients=False):\n",
    "    offset = 0\n",
    "    A, b = [], [] # model all inequalities as A * x <= b\n",
    "    # models the inequalities 3 in the writeup\n",
    "    for i in range(probability_matrix.shape[0]): # iterate over all drivers\n",
    "        a1 = [0] * len(x) # coefficients of inequalities\n",
    "        edges_count = np.count_nonzero(probability_matrix[i] != -1)\n",
    "        edges_probabilities = probability_matrix[i][np.where(probability_matrix[i] != -1)]\n",
    "        assert len(edges_probabilities) == edges_count # sanity check\n",
    "        a1[offset:offset + edges_count] = edges_probabilities\n",
    "#         a2[offset:offset + edges_count] = [1] * edges_count\n",
    "        A.append(a1)\n",
    "#         A.append(a2)\n",
    "        b.append(drivers[i].Bu)\n",
    "#         b.append(drivers[i].quota)\n",
    "        offset += edges_count\n",
    "    \n",
    "    \n",
    "    # Models the inequality -1 * x_f <= 0 for all edges, and x_f <= r_v for all edges\n",
    "    for i in range(len(x)):\n",
    "        a1 = [0] * len(x)\n",
    "        a2 = [0] * len(x)\n",
    "        a1[i] = -1\n",
    "        a2[i] = 1\n",
    "        A.append(a1)\n",
    "        A.append(a2)\n",
    "        b.append(0)\n",
    "        b.append(requests[index_to_coordinate(i,probability_matrix)[1]].arrival_rate)\n",
    "    \n",
    "    # Models inequality 5 and 6 in the writeup\n",
    "    for j in range(probability_matrix.shape[1]):# iterate over all request types\n",
    "        # j -> request; i-> driver\n",
    "        a1 = [0] * len(x)\n",
    "        a2 = [0] * len(x)\n",
    "#         a3 = [0] * len(x)\n",
    "        for i in np.where(probability_matrix[:,j] != -1)[0]:\n",
    "            a1[coordinate_to_index(i, j, probability_matrix)] = 1\n",
    "            a2[coordinate_to_index(i, j, probability_matrix)] = probability_matrix[i,j]\n",
    "#             a3[coordinate_to_index(i, j, probability_matrix)] = 1\n",
    "        A.append(a1)\n",
    "        A.append(a2)\n",
    "#         A.append(a3)\n",
    "        b.append(requests[j].arrival_rate * requests[j].quota)\n",
    "        b.append(requests[j].arrival_rate)\n",
    "#         b.append(requests[j].arrival_rate)\n",
    "    print (len(A), len(b), len(A[0]), len(x))\n",
    "\n",
    "    A, b = m(A).T, m(b)\n",
    "\n",
    "    if not return_coefficients:\n",
    "        print (type(A*x))\n",
    "        inequality = (A * x <= b)\n",
    "        return inequality\n",
    "    else:\n",
    "        return A, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_solution_sanity_check(x_f, x_fair, probability_matrix, requests):\n",
    "    # Sanity Check: sum of all x_f for a request should be less than r_v\n",
    "    for j in range(probability_matrix.shape[1]):\n",
    "        sum_x_f = 0\n",
    "        for i in np.where(probability_matrix[:,j] != -1)[0]:\n",
    "            sum_x_f += x_f.value[coordinate_to_index(i, j, probability_matrix)]\n",
    "        if sum_x_f/(requests[j].arrival_rate * requests[j].quota) > 1:\n",
    "            assert np.isclose(sum_x_f/(requests[j].arrival_rate * requests[j].quota), 1, atol=0.000001, rtol=0) \n",
    "    #     print (min(x_f.value/r.arrival_rate), max(x_f.value/r.arrival_rate))\n",
    "    #     print (min(x_fair.value/r.arrival_rate), max(x_fair.value/r.arrival_rate))\n",
    "    for i in range(len(x_f)):\n",
    "        if x_f.value[i] < 0:\n",
    "            assert np.isclose(x_f.value[i], 0, atol=0.000001, rtol=0)\n",
    "            x_f.value[i] = 0.0\n",
    "        if x_fair.value[i] < 0:\n",
    "            assert np.isclose(x_fair.value[i], 0, atol=0.000001, rtol=0)\n",
    "            x_fair.value[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_fairness_edges_count(matching, drivers):\n",
    "    expected_edge_traversals = [0] * len(drivers)\n",
    "    for match in matching: # note that requests here ensures that edge counts are ordered consistently\n",
    "        if match != None:\n",
    "            expected_edge_traversals[match.u_id] += 1\n",
    "    return np.array(expected_edge_traversals)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GKPS(z, delta_v):\n",
    "#     Z = [0] * len(z)\n",
    "#     z = np.array(z)\n",
    "#     p = z / delta_v\n",
    "#     p = np.append(p,1-sum(p))\n",
    "# #     p.append(1-sum(p))\n",
    "# #     print(p,sum(p))\n",
    "#     for i in range(delta_v):\n",
    "#         sample_z_index = np.random.choice(np.arange(len(z)+1), size=1, p=p)[0]\n",
    "#         if sample_z_index < len(z):\n",
    "#             Z[sample_z_index] = 1\n",
    "#     return Z\n",
    "def GKPS(z, delta_v):\n",
    "    Z = [0] * len(z)\n",
    "    z = np.array(z)\n",
    "    p = z / delta_v\n",
    "    if sum(p) <= 0.00001:\n",
    "        return Z\n",
    "    p = p / sum(p)\n",
    "#     print(p)\n",
    "#     p = np.append(p,1-sum(p))\n",
    "#     p.append(1-sum(p))\n",
    "#     print(p,sum(p))\n",
    "    for i in range(delta_v):\n",
    "        sample_z_index = np.random.choice(np.arange(len(z)), size=1, p=p)[0]\n",
    "        Z[sample_z_index] = 1\n",
    "        p[sample_z_index] = 0\n",
    "#         print(p)\n",
    "        if sum(p) <= 0.00001:\n",
    "            break\n",
    "        else:\n",
    "            p = p / sum(p)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E_v = [1,5,10]\n",
    "# arr = np.arange(len(E_v))\n",
    "# np.random.shuffle(arr)\n",
    "# print(arr)\n",
    "# # print(np.random.shuffle(len(E_v)))\n",
    "# GKPS([0.1,0.2,0.3,0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WarmUp(alpha, beta, request, drivers_copy, probability_matrix, x_f, x_fair):\n",
    "    # There are 2 possible actions, choose assignment based on x_f* (profitable) and y_f* (fair) or reject\n",
    "#     action = np.random.choice(np.arange(2), size=1, p=[alpha + beta, 1 - alpha - beta] if alpha + beta < 1 \\\n",
    "#                               and alpha + beta > 0 else [int(alpha + beta), int(1 - alpha - beta)])[0]\n",
    "    action = np.random.choice(np.arange(3), size=1, p=[alpha, beta, 1-alpha-beta])\n",
    "\n",
    "    if action == 0: #with probability alpha, run SR(x_f)\n",
    "        x_v = x_f\n",
    "    elif action == 1: #with probability beta, run SR(x_fair)\n",
    "        x_v = x_fair\n",
    "    else: \n",
    "        assert alpha + beta < 1, \"If alpha + beta == 1, this should not happen\"\n",
    "        return None\n",
    "    \n",
    "    edge_coordinates, edge_indices, vector_z = [], [], []\n",
    "    for i in np.where(probability_matrix[:,request.u_id] != -1)[0]:\n",
    "        if drivers_copy[i].Bu > 0:\n",
    "            edge_coordinates.append((i, request.u_id))\n",
    "            idx = coordinate_to_index(i, request.u_id, probability_matrix)\n",
    "            edge_indices.append(idx)\n",
    "            vector_z.append(x_v.value[idx]/request.arrival_rate)\n",
    "\n",
    "#     print('alpha:{}, request:{} coming, sample with:{}'.format(alpha,request.u_id,vector_z))\n",
    "    # apply GKPS to z and get binary vector Z    \n",
    "    Z = GKPS(vector_z, request.quota)\n",
    "#     print('Rounding to Z:{}'.format(Z))\n",
    "    # Choose a random permutation π over Ev\n",
    "    rp = np.arange(len(vector_z))\n",
    "    np.random.shuffle(rp)\n",
    "#     print(rp)\n",
    "#     print(edge_coordinates)\n",
    "#     print(Z)\n",
    "    # Follow the order π to process each f = (u, v) ∈ Ev\n",
    "    for z_index in rp:\n",
    "        driver = drivers_copy[edge_coordinates[z_index][0]]\n",
    "#         print(driver)\n",
    "        # Z_f = 1 and u is available then\n",
    "        if Z[z_index] == 1 and driver.Bu > 0:\n",
    "            # Probe the edge f\n",
    "            p_f = probability_matrix[driver.u_id, request.u_id]\n",
    "#             print('try driver:{} with probability:{}'.format(driver.u_id, p_f))\n",
    "            decision = np.random.choice(np.arange(2), size=1, p=[p_f, 1-p_f])[0]\n",
    "            if decision == 0: # user accepted the trip\n",
    "#                 print('driver:{} accepted request:{}'.format(driver.u_id, request.u_id))\n",
    "#                 print (\"User {} accepted driver {}!\".format(request.u_id, driver.u_id))\n",
    "                driver.Bu -= 1\n",
    "                return driver\n",
    "    # Cannot find a matched driver\n",
    "    return None\n",
    "\n",
    "def run_algorithm(all_requests, drivers_copy, probability_matrix, x_f, x_fair, alpha=0.5, beta=0.5):\n",
    "    exact_profit, count = 0, 0\n",
    "#     assert available_drivers == len(drivers_copy)\n",
    "    matches = []\n",
    "#     random.shuffle(all_requests)\n",
    "    for r in all_requests:\n",
    "        matched_driver = WarmUp(alpha, beta, r, drivers_copy, probability_matrix, x_f, x_fair)\n",
    "        matches.append(matched_driver)\n",
    "        if matched_driver is not None:\n",
    "#             print (\"Driver found! : Driver: {}, Request: {}\".format(matched_driver.u_id, r.u_id))\n",
    "#             available_drivers -= 1\n",
    "#             assert available_drivers == count_available_drivers(drivers_copy)\n",
    "            if (abs(matched_driver.latitude-r.start_latitude)+abs(matched_driver.longitude-r.start_longitude)) == 0:\n",
    "                exact_profit += r.distance\n",
    "            else:\n",
    "                exact_profit += 0.8 * r.distance\n",
    "            count += 1\n",
    "    return exact_profit, count, matches\n",
    "\n",
    "# def count_available_drivers(drivers_copy):\n",
    "#     count = 0\n",
    "#     for d in drivers_copy:\n",
    "#         if d.is_present:\n",
    "#             count += 1\n",
    "#     return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_greedy(all_requests, drivers_copy, probability_matrix, profit_matrix):\n",
    "    matches, profit = [], 0\n",
    "    for request in all_requests:\n",
    "        available_drivers, profits = [], []\n",
    "        for idx in np.where(probability_matrix[:,request.u_id] != -1)[0]:\n",
    "            assert drivers_copy[idx].u_id == idx\n",
    "            if drivers_copy[idx].is_present:\n",
    "                available_drivers.append(drivers_copy[idx])\n",
    "                assert probability_matrix[idx, request.u_id] != -1\n",
    "                profits.append(profit_matrix[idx, request.u_id])\n",
    "        if len(available_drivers) == 0:\n",
    "            assigned_driver = None\n",
    "        else:\n",
    "            assigned_driver = driver_acceptance(available_drivers[np.argmax(profits)], \n",
    "                                                    request, probability_matrix)\n",
    "        matches.append(assigned_driver)\n",
    "        if assigned_driver is not None:\n",
    "            profit += request.distance\n",
    "    return matches, profit\n",
    "\n",
    "def run_uniform(all_requests, drivers_copy, probability_matrix):\n",
    "    matches, profit = [], 0\n",
    "    for r in all_requests:\n",
    "        driver_idx = np.random.choice(np.where(probability_matrix[:,r.u_id] != -1)[0], size=1)[0]\n",
    "        assert drivers_copy[driver_idx].u_id == driver_idx\n",
    "        assert probability_matrix[driver_idx, r.u_id] != -1\n",
    "        assigned_driver = driver_acceptance(drivers_copy[driver_idx], r, probability_matrix)\n",
    "        matches.append(assigned_driver)\n",
    "        if assigned_driver is not None:\n",
    "            profit += r.distance\n",
    "    return matches, profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fairness_from_array(edges_count, num_loops, drivers):\n",
    "    fairness_counts_all_runs = np.array(edges_count)\n",
    "#     error_counts = np.min(fairness_counts, axis=1) # will be used to calculate fairness for each run\n",
    "#     print (error_counts)\n",
    "#     error_args = np.argmin(fairness_counts, axis=1)\n",
    "#     assert len(error_counts) == num_loops and len(error_args) == num_loops\n",
    "#     for i in range(len(error_args)):\n",
    "#         error_counts[i] /= requests[error_args[i]].arrival_rate\n",
    "    fairness_counts = np.sum(fairness_counts_all_runs, axis=0)/num_loops\n",
    "    for idx in range(len(drivers)):\n",
    "        fairness_counts[idx] /= drivers[idx].Bu\n",
    "    \n",
    "#     print(requests[np.argmin(fairness_counts)].arrival_rate)\n",
    "#     fairness_error = np.std(\n",
    "#         fairness_counts_all_runs[:,np.argmin(fairness_counts)] / \\\n",
    "#         requests[np.argmin(fairness_counts)].arrival_rate)\n",
    "#     print (fairness_error)\n",
    "    \n",
    "    return np.min(fairness_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_results(all_requests, drivers, probability_matrix, x_f, x_fair, alphas, num_loops):\n",
    "    algorithm_params = []\n",
    "    for alpha in alphas:\n",
    "        for i in range(num_loops):\n",
    "            algorithm_params.append([all_requests[i], [copy.deepcopy(d) for d in drivers], \n",
    "                                     probability_matrix, x_f, x_fair, alpha, 1-alpha])\n",
    "\n",
    "    with Pool(multiprocessing.cpu_count()) as p:\n",
    "        matching_results = p.starmap(run_algorithm, algorithm_params)\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_edges_count_results(all_requests, matching_results, requests):\n",
    "#     fairness_measure_params = []\n",
    "#     for matching_result in matching_results:\n",
    "#         fairness_measure_params.append([all_requests, matching_result[2], requests])\n",
    "\n",
    "#     with Pool(multiprocessing.cpu_count()) as p:\n",
    "#         edges_count_results = p.starmap(measure_fairness_edges_count, fairness_measure_params)\n",
    "#     return edges_count_results\n",
    "def get_edges_count_results(matching_results, drivers):\n",
    "    fairness_measure_params = []\n",
    "    for matching_result in matching_results:\n",
    "        fairness_measure_params.append([matching_result[2], drivers])\n",
    "\n",
    "    with Pool(multiprocessing.cpu_count()) as p:\n",
    "        edges_count_results = p.starmap(measure_fairness_edges_count, fairness_measure_params)\n",
    "    return edges_count_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit_fairness_crs(matching_results, edges_count_results, num_loops, \n",
    "                            requests, alphas, optimal_profit, optimal_fairness):\n",
    "    profit_crs, profit_errors, fairness_crs, fairness_errors = [], [], [], []\n",
    "    for j in range(len(alphas)):\n",
    "        expected_profit, std_dev_profit = 0, []\n",
    "        for i in range(num_loops):\n",
    "            expected_profit += matching_results[j * num_loops + i][0]\n",
    "            std_dev_profit.append(matching_results[j * num_loops + i][0])\n",
    "        expected_profit /= num_loops\n",
    "        std_dev_profit = np.std(std_dev_profit)\n",
    "        profit_crs.append(expected_profit/optimal_profit)\n",
    "        profit_errors.append(std_dev_profit/optimal_profit)\n",
    "\n",
    "        fairness_measure = calculate_fairness_from_array(\n",
    "            edges_count_results[j*num_loops:(j+1)*num_loops], num_loops, drivers)\n",
    "        print (expected_profit/optimal_profit, fairness_measure/optimal_fairness)\n",
    "        fairness_std_dev = 0\n",
    "        fairness_crs.append(fairness_measure/optimal_fairness)\n",
    "        fairness_errors.append(fairness_std_dev/optimal_fairness)\n",
    "    return profit_crs, profit_errors, fairness_crs, fairness_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_T(requests):\n",
    "    return np.sum([r.arrival_rate for r in requests])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
